# Database Configuration
DATABASE_PATH=models.db

# Cache Configuration
# Primary cache (fast SSD) for frequently used models
# IMPORTANT: Point to BASE huggingface directory, not the 'hub' subdirectory
# For shared cache between local and Docker, use project directory: ./hf-cache
# For separate caches, use default: ~/.cache/huggingface
PRIMARY_CACHE_PATH=/home/jare16/LLM/hf-cache
PRIMARY_CACHE_LIMIT_GB=100

# Secondary cache (slower drive) for infrequently used models
SECONDARY_CACHE_PATH=/mnt/z/llm-models-cache
SECONDARY_CACHE_LIMIT_GB=2000

# Cache usage warning threshold (0.9 = 90%)
CACHE_WARNING_THRESHOLD=0.9

# GPU Configuration (Optional)
HIP_VISIBLE_DEVICES=0
PYTORCH_HIP_ALLOC_CONF=garbage_collection_threshold:0.6,max_split_size_mb:128

# HuggingFace Configuration (Optional)
# Uncomment and set if you need to access gated models
# HF_TOKEN=your_huggingface_token_here
